# åŸºäºèŒ¶å¶æ•°æ®çš„çŸ¥è¯†å›¾è°±+RAG+æœ¬åœ°å¤§æ¨¡å‹éƒ¨ç½²é¡¹ç›®æ€»ç»“
## é¡¹ç›®ä»‹ç»
ä»¥ç™¾ç§‘ç½‘ç«™çš„èŒ¶å¶æ•°æ®ä¸ºåŸºç¡€ï¼Œä½¿ç”¨Ollamaæœ¬åœ°éƒ¨ç½²å¤§é¢„è¨€æ¨¡å‹ï¼ˆ***Large Language Modelï¼ŒLLM***ï¼‰ï¼Œç»“åˆå¸¦æœ‰çŸ¥è¯†å›¾è°±ï¼ˆ***Knowledge Graphï¼ŒKG***ï¼‰çš„æ£€ç´¢å¢å¼ºç”Ÿæˆï¼ˆ***Retrieval-Augmented Generationï¼ŒRAG***ï¼‰æŠ€æœ¯ï¼Œå¦‚**GraphRAG**ã€**LightRAG**ï¼Œä»¥å®ç°å¢å¼ºå¤§æ¨¡å‹åœ¨å‚ç›´é¢†åŸŸçš„é—®ç­”èƒ½åŠ›ï¼Œå‡å¼±å¤§æ¨¡å‹å› å‚ç›´é¢†åŸŸçŸ¥è¯†ç¼ºä¹å¸¦æ¥çš„å¹»è§‰é—®é¢˜ã€‚


## ç›®å½•
- [æ¶‰åŠæŠ€æœ¯](#æ¶‰åŠæŠ€æœ¯)
    - [çˆ¬è™«](#1-çˆ¬è™«)
    - [çŸ¥è¯†å›¾è°±](#2-çŸ¥è¯†å›¾è°±)
    - [GraphRAG](#3-graphrag)
    - [LightRAG](#4-lightrag)
    - [Ollamaæœ¬åœ°éƒ¨ç½²å¤§æ¨¡å‹](#5-ollamaæœ¬åœ°éƒ¨ç½²å¤§æ¨¡å‹)
    - [RAGè¯„åˆ†ç³»ç»Ÿ](#RAGè¯„åˆ†ç³»ç»Ÿ)
- [ä»£ç è§£æ](#ä»£ç è§£æ)
  - [çˆ¬è™«](#çˆ¬è™«crawler)
  - [GraphRAG](#ä¿®æ”¹graphragæºç )
  - [LightRAG](#åˆå§‹åŒ–ragç³»ç»Ÿ)
- [è¿è¡ŒRAGç³»ç»Ÿ](#è¿è¡Œragç³»ç»Ÿ)
  - [è¿è¡ŒGraphRAG](#è¿è¡Œgraphrag)
  - [è¿è¡ŒLightRAG](#è¿è¡Œlightrag)
- [é¡¹ç›®æ–‡ä»¶è§£é‡Š](#é¡¹ç›®æ–‡ä»¶è§£é‡Š)
- [TODO](#todo-list)
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)


## æ¶‰åŠæŠ€æœ¯
### 1. çˆ¬è™«
ä½¿ç”¨``DrissionPage``åº“ï¼ˆ[å®˜æ–¹ç½‘ç«™][DrissionPage]ï¼Œ[githubåœ°å€][DrissionPage_github]ï¼‰ï¼Œä»ç½‘ç»œä¸Šçˆ¬å–èŒ¶å¶ç™¾ç§‘çš„é¡µé¢ï¼Œå¹¶æå–å‡ºå…¶ä¸­çš„ä¿¡æ¯ã€‚         
- çˆ¬å–é¡µé¢çš„æ ‡é¢˜
- çˆ¬å–é¡µé¢çš„ä»‹ç»éƒ¨åˆ†
- çˆ¬å–é¡µé¢çš„ç»“æ„åŒ–æ•°æ®
- çˆ¬å–é¡µé¢çš„éç»“æ„åŒ–æ•°æ®
- è¯¥é¡µé¢æ˜¯ä»å“ªä¸ªæ ‡é¢˜é¡µé¢è·³è½¬è¿‡æ¥çš„
- è¯¥é¡µé¢å­˜åœ¨çš„å›¾ç‰‡è·¯å¾„ä¸å…¶å¯¹åº”çš„å›¾æ ‡é¢˜
- è¯¥é¡µé¢çš„ç½‘å€
- è¯¥ç½‘é¡µæ ‡é¢˜çš„è¯æ¡ï¼ˆåˆ†ç±»ï¼‰

### 2. çŸ¥è¯†å›¾è°±
è½¬è½½å¾®ä¿¡å…¬ä¼—å·æ¨æ–‡[ã€Šå¤§å‚æŠ€æœ¯å®ç° | è¯¦è§£çŸ¥è¯†å›¾è°±çš„æ„å»ºå…¨æµç¨‹ã€‹][Knowledge Graph]

### 3. GraphRAG
***è¯¦æƒ…å‚è€ƒå¾®è½¯[å®˜æ–¹æ–‡æ¡£][GraphRAG]ï¼ˆ[githubæ–‡æ¡£][GraphRAG_github]ï¼‰***  
GraphRAGçš„IIndexingå¤§è‡´æµç¨‹å¦‚ä¸‹ï¼š  
![](assets/GraphRAG.png)
#### é˜¶æ®µä¸€ï¼šæ–‡æœ¬åˆ†å—
å°†ç”¨æˆ·ä¼ å…¥çš„æ–‡æ¡£æŒ‰ç…§``chunk_size``å‚æ•°å¤§å°è¿›è¡Œåˆ†å—ï¼Œä½œç”¨äºåç»­çš„çŸ¥è¯†æå–ï¼Œå¹¶ä¸”æå–å‡ºçš„ä¿¡æ¯å¯ä»¥è¿½æº¯åˆ°å…¶åŸå§‹çš„æ–‡æœ¬ã€‚
![](assets/GraphRAG-Chunking.png)
#### é˜¶æ®µäºŒï¼šå›¾å½¢æå–
ä½¿ç”¨LLMå¯¹åˆ†å‰²å‡ºçš„æ–‡æœ¬å—è¿›è¡Œä¿¡æ¯æå–å¹¶ç”Ÿæˆæ‘˜è¦ã€‚
![](assets/GraphRAG-Extraction.png)
å…¶ä¸­ï¼Œæå–çš„ç›®æ ‡åŒ…æ‹¬ï¼š**å®ä½“{entities}**ã€**å…³ç³»{relationships}** ä»¥åŠ ***å£°æ˜{claims}ï¼ˆå¯é€‰ï¼‰***ã€‚  
æå–å‡ºçš„å®ä½“å’Œå…³ç³»å°†å½¢æˆä¸¤ä¸ªåˆ—è¡¨ï¼Œå…¶ä¸­ä¸€ä¸ªå«æœ‰**å®ä½“åç§°**ã€**å®ä½“ç±»å‹**ã€**å®ä½“æè¿°ï¼ˆæ‘˜è¦ï¼‰**ï¼›å¦ä¸€ä¸ªåˆ™åŒ…å«**å¤´å®ä½“**ã€**å°¾å®ä½“**ã€**å…³ç³»æè¿°ï¼ˆæ‘˜è¦ï¼‰**ã€‚  
å…¶ä¸­çš„æ‘˜è¦ä¿¡æ¯åŒæ ·æ˜¯ç”±å¤§æ¨¡å‹ç”Ÿæˆå¾—åˆ°çš„ï¼Œåœ¨æ­¤é˜¶æ®µæˆ‘ä»¬å¯ä»¥è¯´å¾—åˆ°äº†ä¸€ä¸ªåŒ…å«å®ä½“ä¸å…³ç³»çš„å›¾è°±ã€‚
#### é˜¶æ®µä¸‰ï¼šå›¾å½¢å¢å¼º
ä½¿ç”¨***Leiden Hierarchical***ç®—æ³•è¿›è¡Œç¤¾åŒºæ£€æµ‹ï¼Œå³ç”Ÿæˆå®ä½“ç¤¾åŒºçš„å±‚æ¬¡ç»“æ„ã€‚ç”¨ä¸ä¸¥è°¨çš„è¯æ¥è¯´ï¼Œå°±æ˜¯å°†å®ä½“è¿›è¡Œèšç±»ï¼Œæ¯ä¸€å±‚åˆ™æ˜¯ä¸€ä¸ªç¤¾åŒºã€‚
![](assets/GraphRAG-Augmentation.png)
#### é˜¶æ®µå››ï¼šç¤¾åŒºæ€»ç»“
ä½¿ç”¨LLMï¼Œæ ¹æ®ä¸Šè¿°æ­¥éª¤å¾—åˆ°çš„ç¤¾åŒºæ•°æ®ï¼Œå¯¹æ¯ä¸€ä¸ªç¤¾åŒºç”Ÿæˆ**ç¤¾åŒºæŠ¥å‘Š**ï¼ŒåŒæ—¶å¯¹æŠ¥å‘Šè¿›è¡Œ**æ‘˜è¦æå–**ã€‚  
![](assets/GraphRAG-Community.png)
#### é˜¶æ®µäº”ï¼šæ–‡æ¡£å¤„ç†
å°†æ‰€æœ‰æ–‡æ¡£ä¸ç¬¬ä¸€é˜¶æ®µç”Ÿæˆçš„æ–‡æœ¬å—è¿›è¡Œ**é“¾æ¥**ã€‚  
![](assets/GraphRAG-Document.png)
#### é˜¶æ®µå…­ï¼šå‘é‡åŒ–å¤„ç†
å°†ç”Ÿæˆçš„å®ä½“ã€å…³ç³»ã€ç¤¾åŒºç­‰ä¿¡æ¯è¿›è¡Œ**å‘é‡åŒ–**å¤„ç†ã€‚
![](assets/GraphRAG-Embedding.png)

***ä¸Šè¿°ä¿¡æ¯å‡å¼•ç”¨è‡ª[å¾®è½¯GraphRAGå®˜æ–¹æ–‡æ¡£][GraphRAG]***  

### 4. LightRAG
***è¯¦æƒ…å‚è€ƒ[å®˜æ–¹æ–‡æ¡£][LightRAG_github]***  
LightRAGåŒæ ·æ˜¯ä¸€ç§å°†å›¾è°±ä¸RAGä½œç»“åˆçš„æŠ€æœ¯ã€‚  
LightRAGç”±é¦™æ¸¯å¤§å­¦äººå‘˜å¼€å‘ï¼Œé‡‡ç”¨åŒå±‚æ£€ç´¢ç³»ç»Ÿï¼Œå‡è½»äº†GraphRAGä¸­åŸºäºç¤¾åŒºçš„éå†ç›¸å…³çš„è®¡ç®—å¼€é”€å’Œç¼“æ…¢ã€è€—æ—¶çš„æŒ‘æˆ˜ã€‚
#### Indexing
LightRAGçš„IIndexingå¤§è‡´æµç¨‹å¦‚ä¸‹ï¼š  
![](assets/LightRAG-Indexing.png)
##### é˜¶æ®µä¸€ï¼šæ–‡æœ¬åˆ†å—
ä¸GraphRAGç›¸åŒï¼ŒåŒæ ·æ˜¯å°†ä¼ å…¥çš„æ–‡æœ¬è¿›è¡Œ**åˆ†å—**ã€‚
##### é˜¶æ®µäºŒï¼šå®ä½“ä¸å…³ç³»æå–
ä½¿ç”¨LLMï¼Œå¯¹æ–‡æœ¬å—è¿›è¡Œä¿¡æ¯æå–ï¼Œå°†**å®ä½“**ä¸**å…³ç³»**æå–å‡ºæ¥ã€‚  
##### é˜¶æ®µä¸‰ï¼šç”Ÿæˆå®ä½“/å…³ç³»é”®å€¼å¯¹
åœ¨è¿™é˜¶æ®µï¼ŒLLMå°†å¯¹å®ä½“æˆ–å…³ç³»è¿›è¡Œåˆ†æï¼Œå¹¶ç”Ÿæˆæ€»ç»“æ€§çš„æ–‡æœ¬æ®µï¼ˆå¯ä»¥è¯´æ˜¯æ‘˜è¦æˆ–æè¿°ï¼‰ï¼Œæ„å»º**å®ä½“/å…³ç³»é”®å€¼å¯¹**ã€‚  
å…¶ä¸­ï¼Œ é”®ï¼ˆKeyï¼‰ä¸ºå®ä½“æˆ–å…³ç³»çš„åç§°ï¼Œå€¼ä¸ºLLMç”Ÿæˆçš„æ‘˜è¦ã€‚ä¾‹å­å¦‚ä¸‹ï¼š  
![](assets/LightRAG-Example.png)
##### é˜¶æ®µå››ï¼šåˆå§‹åŒ–å›¾è°±
æ ¹æ®å¾—åˆ°çš„å®ä½“ä¸å…³ç³»ï¼Œ**æ„å»ºå›¾è°±**çš„èŠ‚ç‚¹ä¸å…³ç³»ï¼Œå¾—åˆ°ä¸€ä¸ªåˆå§‹çš„å›¾è°±ã€‚
##### é˜¶æ®µäº”ï¼šå›¾è°±å»é‡
**ä¼˜åŒ–å›¾è°±**ï¼ŒæŠŠé‡å¤çš„å®ä½“å’Œå…³ç³»åˆå¹¶ï¼Œå‡å°‘æ£€ç´¢çš„å¼€é”€ä¸ç¼©å°å›¾å½¢çš„å¤§å°ï¼Œå¾—åˆ°æœ€ç»ˆä¼˜åŒ–åçš„å›¾è°±ã€‚
##### é˜¶æ®µå…­ï¼šå‘é‡åŒ–
å°†æ•°æ®è¿›è¡Œ**å‘é‡åŒ–**å­˜å‚¨ã€‚
#### Retrieval and Query  
LightRAGçš„æŸ¥è¯¢å¤§è‡´æµç¨‹å¦‚ä¸‹ï¼š  

![](assets/LightRAG-Query.png)

å°†ç”¨æˆ·çš„é—®é¢˜è¿›è¡Œå¤„ç†ï¼Œå¾—åˆ°å¯¹åº”çš„æŸ¥è¯¢**å…³é”®è¯**ï¼Œå°†å…³é”®è¯åœ¨å‘é‡æ•°æ®åº“ä¸çŸ¥è¯†å›¾è°±ä¸­è¿›è¡Œ**åŒ¹é…**ï¼Œå¾—åˆ°æœ€ç›¸å…³çš„**å®ä½“**æˆ–**å…³ç³»**ã€‚æ¥ç€è·å–**é‚»å±…èŠ‚ç‚¹**ï¼Œæœ€ç»ˆè·å–åˆ°èŠ‚ç‚¹ä¸å…³ç³»å¯¹åº”çš„**æ–‡æœ¬å—**ï¼Œå°†æ£€ç´¢åˆ°çš„ä¿¡æ¯æä¾›ç»™LLMï¼Œæœ€ç»ˆç”Ÿæˆå›ç­”ã€‚  

***ä¸Šè¿°ä¿¡æ¯å‡å¼•ç”¨è‡ª[LearnOpenCV][LightRAG_LearnOpenCV]ä¸[LightRAGå®˜æ–¹æ–‡æ¡£][LightRAG_github]***

### 5. Ollamaæœ¬åœ°éƒ¨ç½²å¤§æ¨¡å‹
[Ollama][Ollama_github]æ˜¯ä¸€ä¸ªèƒ½åœ¨æœ¬åœ°æœºå™¨ä¸Šå¿«é€Ÿéƒ¨ç½²è¿è¡ŒLLMçš„å¼€æºå·¥å…·ã€‚  
#### ä¸‹è½½
å‰å¾€[Ollamaå®˜ç½‘][Ollama]ä¸‹è½½Ollamaï¼Œå¿«é€Ÿéƒ¨ç½²æœ¬åœ°å¤§æ¨¡å‹ã€‚  
![](assets/Ollama.png)
ç»ˆç«¯è¾“å…¥å‘½ä»¤å¯åŠ¨OllamaæœåŠ¡ï¼ŒæœåŠ¡é»˜è®¤ç«¯å£å·ä¸º11434ã€‚
```bash
ollama serve
```
#### æ‹‰å–æ¨¡å‹
åœ¨Ollamaå®˜ç½‘æœç´¢å¯æ‹‰å–çš„æ¨¡å‹ ã€‚
![](assets/Ollama-Search.png)
é€‰å–ç›®æ ‡æ¨¡å‹ï¼ˆä»¥**deepseek-r1çš„32b**æ¨¡å‹ä¸ºä¾‹ï¼‰ï¼Œåœ¨ç»ˆç«¯è¿è¡Œå‘½ä»¤ã€‚
```bash
ollama pull deepseek-r1:32b
```
åœ¨æ¨¡å‹æ–‡ä»¶ä¸‹è½½å®Œæˆåï¼Œåœ¨ç»ˆç«¯è¾“å…¥å‘½ä»¤ï¼ŒæŸ¥çœ‹å·²ç»æ‹‰å–å®Œæˆçš„æ¨¡å‹åˆ—è¡¨ã€‚
```bash
ollama list
```
![](assets/Ollama-list.png)
#### è¿è¡Œæ¨¡å‹
åœ¨ç»ˆç«¯è¾“å…¥å‘½ä»¤ï¼Œå¯åŠ¨æ¨¡å‹ã€‚
```bash
ollama run deepseek-r1:32b
```
![](assets/Ollama-run.png)
å¯ä»¥çœ‹åˆ°æ¨¡å‹å·²ç»æˆåŠŸéƒ¨ç½²åœ¨æ˜¾å¡ä¸Šã€‚
![](assets/nvidia-smi.png)
è¿™æ—¶å°±å·²ç»å¯ä»¥ä¸å¤§æ¨¡å‹è¿›è¡Œäº¤äº’äº†ã€‚
![](assets/Hello.png)
éœ€è¦åœæ­¢æ¨¡å‹è¿è¡Œï¼Œåˆ™è¾“å…¥å‘½ä»¤ã€‚
```bash
ollama stop deepseek-r1:32b
```

æ›´å¤šåŠŸèƒ½è¯·è¾“å…¥å‘½ä»¤æˆ–***å‰å¾€[Ollama][Ollama_github]æŸ¥çœ‹ã€‚***
```bash
ollama --help
```

### 6. RAGç³»ç»Ÿè¯„åˆ†
å¯ä½¿ç”¨è¯„åˆ†å·¥å…·[ragas][ragas]å’Œ[RAGChecker][RAGChecker]å¯¹RAGç³»ç»Ÿè¿›è¡Œå¤šæ–¹é¢çš„è¯„ä¼°ã€‚  
~~å› ä¸ºä¸å¯æŠ—åŠ›åŸå› ï¼Œè¯„åˆ†æ•°æ®é›†è¿Ÿè¿Ÿæ„å»ºä¸å‡ºæ¥ğŸ˜¢~~

## ä»£ç è§£æ
### çˆ¬è™«(Crawler)
#### spider_baidu_baike.pyï¼ˆæ ¸å¿ƒï¼‰

è¯¥ç±»ç”¨äºçˆ¬å–ç™¾ç§‘ï¼Œåœ¨æŒ‡å®šçš„è·¯å¾„ä¸‹ä¿å­˜çˆ¬å–ç»“æœã€‚
```python
class spider_baike:
```
åˆå§‹åŒ–å¯é€‰æ‹©3ä¸ªå‚æ•°ï¼š
1. ``save_path``é€‰æ‹©ä¿å­˜æ–‡ä»¶çš„è·¯å¾„ï¼ˆå¿…é¡»æ˜¯jsonåç¼€ï¼‰
2. ``visible``é€‰æ‹©çˆ¬å–ç»“æœæ˜¯è¾¹çˆ¬è¾¹å­˜è¿˜æ˜¯å…¨éƒ¨çˆ¬å®Œå†å­˜
3. ``edge_path``é€‰æ‹©chromeå†…æ ¸æµè§ˆå™¨çš„è·¯å¾„ï¼Œé»˜è®¤ä¸º  
   "C:\\Program Files (x86)\\Microsoft\\Edge\\Application\\msedge.exe"ï¼ˆåœ¨è·å–å›¾ç‰‡è·¯å¾„æ—¶éœ€ç”¨åˆ°æµè§ˆå™¨ï¼‰  

åœ¨åˆ›å»ºå®Œçˆ¬è™«ç±»åï¼Œè°ƒç”¨ç±»å†…å‡½æ•°``run()``å³å¯å¼€å§‹çˆ¬å–ç½‘é¡µï¼Œè€Œçˆ¬å–ç½‘é¡µå¯é€šè¿‡ä¸¤ç§æ–¹å¼æŒ‡å®šï¼š  
1. ä¼ å…¥å¾…çˆ¬å–çš„ç™¾ç§‘è¯æ¡åˆ—è¡¨``search_name``
2. ä¼ å…¥éœ€çˆ¬å–çš„ç™¾ç§‘ç½‘å€``url``  

è¿™ä¸¤ä¸ªå‚æ•°é€‰å…¶ä¸€æŒ‡å®šå³å¯ï¼Œè‹¥ä¸¤è€…éƒ½å¡«å†™ï¼Œåˆ™ä»¥``url``ä¸ºå‡†ã€‚æ­¤å¤–ï¼Œ``run()``ä»å¯ä¼ å…¥``max_depth``å‚æ•°ï¼Œç”¨äºæŒ‡å®šçˆ¬å–çš„æ·±åº¦ï¼Œé»˜è®¤ä¸º0ï¼Œå³ä¸è¿›è¡Œé¡µé¢è·³è½¬ã€‚  
è‹¥éœ€è¦çˆ¬å–æ¡ç›®ä¸º"ç»¿èŒ¶"çš„ç™¾ç§‘ç½‘é¡µä»¥åŠè¯¥ç½‘é¡µå¯ä»¥è·³è½¬çš„å…¶ä»–ç™¾ç§‘æ¡ç›®ä¿¡æ¯ï¼Œå³å¯æŒ‡å®šå‚æ•°å¦‚ä¸‹ï¼š
```python
spider = spider_baike(save_path="your_path/file.json")
spider.run(search_name=["ç»¿èŒ¶"], max_depth=1)
```

#### my_json2txt.pyï¼ˆå¯é€‰ï¼‰
è¯¥å‡½æ•°ç”¨äºå°†çˆ¬å–ä¸‹æ¥çš„jsonæ–‡ä»¶è½¬åŒ–ä¸ºæŒ‡å®šæ ¼å¼txtæ–‡æœ¬ã€‚
```python
def json2txt(json_path, txt_path):
```
å…¶ä¸­ï¼Œ``json_path``ä¸ºjsonæ–‡ä»¶è·¯å¾„ï¼Œ``txt_path``ä¸ºä¿å­˜çš„txtæ–‡ä»¶è·¯å¾„ã€‚  
æ­¤å¤–ï¼Œå‡½æ•°æ”¯æŒæŒ‡å®š``json_file``å‚æ•°ï¼Œç”¨äºå­˜äº**å†…å­˜**ä¸­çš„DataFrameå˜é‡ï¼Œè€Œä¸æ˜¯ä»ç¡¬ç›˜ä¸­è¯»å–ã€‚å½“``json_path``ä¸``json_file``åŒæ—¶æŒ‡å®šæ—¶ï¼Œ``json_file``ä¼˜å…ˆçº§æ›´é«˜ã€‚  
è¯¥å‡½æ•°è¿˜èƒ½æŒ‡å®šè½¬æ¢çš„èµ·å§‹ç´¢å¼•``start_idx``ä¸ç»ˆæ­¢ç´¢å¼•``end_idx``ï¼Œç”¨äºæŒ‡å®šè½¬æ¢çš„èŒƒå›´ã€‚  

è½¬æ¢è§„åˆ™å¦‚ä¸‹ï¼š
```txt
"æ ‡é¢˜"  ->  == "æ ‡é¢˜" ==
"è¯æ¡"  ->  "æ ‡é¢˜"æ˜¯"è¯æ¡"
"ä»‹ç»"  ->  -- "æ ‡é¢˜"çš„"ä»‹ç»" -- \ "ä»‹ç»å†…å®¹"
"ç»“æ„åŒ–æ•°æ®"  ->  - "æ ‡é¢˜"çš„"Key":"Value"

"éç»“æ„åŒ–æ•°æ®"  å¦‚ä¸‹ï¼š
"h2"  ->  -- "æ ‡é¢˜"çš„"h2" -- \ "h2å†…å®¹"
"h3"  ->  ~~ "h3" ~~ \ "h3å†…å®¹"

"ç½‘å€"  ->  -- "æ ‡é¢˜"çš„ä¿¡æ¯æ¥æº -- \ æ¥æºä¸ºç™¾åº¦ç™¾ç§‘ï¼Œåœ°å€ä¸º"ç½‘å€"

"æœªçˆ¬å–åˆ°å†…å®¹"  ->  "ç©ºè¡Œè¡¨ç¤º"
```
è½¬æ¢å‰åå˜åŒ–å±•ç¤ºï¼š  
[æœªè½¬å˜çš„jsonæ–‡ä»¶](examples/data/unprocessed.json)  
[è½¬å˜åçš„txtæ–‡æœ¬](examples/data/processed.txt)

### GraphRAG
#### ä¿®æ”¹GraphRAGæºç 
å› GraphRAGä»…åšäº†OpenAIæ¥å£ï¼Œè€ŒOllamaçš„APIè°ƒç”¨ä¸OpenAIè°ƒç”¨è¯­æ³•ç•¥æœ‰ä¸åŒï¼ˆåœ¨Embeddingæ¨¡å‹è°ƒç”¨æ—¶ï¼‰ï¼Œæ•…ä¿®æ”¹GraphRAGçš„ä»£ç ä»¥æ”¯æŒOllamaè°ƒç”¨æœ¬åœ°Embeddingæ¨¡å‹ã€‚[å‚è€ƒèµ„æ–™åœ¨è¿™][CSDN_GraphRAG]ã€‚
##### 1. ä¿®æ”¹graphrag/llm/openai/openai_embeddings_llm.py
åœ¨ä»£ç ä¸­æ‰¾åˆ°
```python
embedding = await self.client.embeddings.create(
    input=input,
    **args,
)
return [d.embedding for d in embedding.data]
```
å°†å…¶æ³¨é‡Šï¼Œä¿®æ”¹ä¸º
```python
# ä»¥ä¸‹æ˜¯å¢æ·»çš„ollama embeddingä»£ç 
embedding_list = []
for inp in input:
    embedding = ollama.embeddings(model="your_embedding_model_name",prompt=inp)
    embedding_list.append(embedding["embedding"])
return embedding_list

# ä»¥ä¸‹æ˜¯åŸä»£ç çš„embeddingå†™æ³•
# embedding = await self.client.embeddings.create(
#     input=input,
#     **args,
# )
# return [d.embedding for d in embedding.data]
```
##### 2. ä¿®æ”¹graphrag/query/llm/oai/embedding.py
é—®é¢˜åŒæ ·æ˜¯Embeddingçš„è°ƒç”¨ï¼Œå¯è‡ªè¡Œä¿®æ”¹æˆ–ç›´æ¥ç”¨ä¸‹æ–¹ä»£ç è¦†ç›–åŸæ–‡ä»¶ä»£ç ã€‚
```python
# æ—§çš„embedding
# Copyright (c) 2024 Microsoft Corporation.
# Licensed under the MIT License

"""OpenAI Embedding model implementation."""

import asyncio
from collections.abc import Callable
from typing import Any

import numpy as np
import tiktoken
from tenacity import (
    AsyncRetrying,
    RetryError,
    Retrying,
    retry_if_exception_type,
    stop_after_attempt,
    wait_exponential_jitter,
)

from graphrag.query.llm.base import BaseTextEmbedding
from graphrag.query.llm.oai.base import OpenAILLMImpl
from graphrag.query.llm.oai.typing import (
    OPENAI_RETRY_ERROR_TYPES,
    OpenaiApiType,
)
from graphrag.query.llm.text_utils import chunk_text
from graphrag.logging import StatusLogger

from langchain_community.embeddings import OllamaEmbeddings



class OpenAIEmbedding(BaseTextEmbedding, OpenAILLMImpl):
    """Wrapper for OpenAI Embedding models."""

    def __init__(
        self,
        api_key: str | None = None,
        azure_ad_token_provider: Callable | None = None,
        model: str = "text-embedding-3-small",
        deployment_name: str | None = None,
        api_base: str | None = None,
        api_version: str | None = None,
        api_type: OpenaiApiType = OpenaiApiType.OpenAI,
        organization: str | None = None,
        encoding_name: str = "cl100k_base",
        max_tokens: int = 8191,
        max_retries: int = 10,
        request_timeout: float = 180.0,
        retry_error_types: tuple[type[BaseException]] = OPENAI_RETRY_ERROR_TYPES,  # type: ignore
        reporter: StatusLogger | None = None,
    ):
        OpenAILLMImpl.__init__(
            self=self,
            api_key=api_key,
            azure_ad_token_provider=azure_ad_token_provider,
            deployment_name=deployment_name,
            api_base=api_base,
            api_version=api_version,
            api_type=api_type,  # type: ignore
            organization=organization,
            max_retries=max_retries,
            request_timeout=request_timeout,
            reporter=reporter,
        )

        self.model = model
        self.encoding_name = encoding_name
        self.max_tokens = max_tokens
        self.token_encoder = tiktoken.get_encoding(self.encoding_name)
        self.retry_error_types = retry_error_types

    def embed(self, text: str, **kwargs: Any) -> list[float]:
        """
        Embed text using OpenAI Embedding's sync function.

        For text longer than max_tokens, chunk texts into max_tokens, embed each chunk, then combine using weighted average.
        Please refer to: https://github.com/openai/openai-cookbook/blob/main/examples/Embedding_long_inputs.ipynb
        """
        token_chunks = chunk_text(
            text=text, token_encoder=self.token_encoder, max_tokens=self.max_tokens
        )
        chunk_embeddings = []
        chunk_lens = []
        for chunk in token_chunks:
            try:
                embedding, chunk_len = self._embed_with_retry(chunk, **kwargs)
                chunk_embeddings.append(embedding)
                chunk_lens.append(chunk_len)
            # TODO: catch a more specific exception
            except Exception as e:  # noqa BLE001
                self._reporter.error(
                    message="Error embedding chunk",
                    details={self.__class__.__name__: str(e)},
                )

                continue
        chunk_embeddings = np.average(chunk_embeddings, axis=0, weights=chunk_lens)
        chunk_embeddings = chunk_embeddings / np.linalg.norm(chunk_embeddings)
        return chunk_embeddings.tolist()

    async def aembed(self, text: str, **kwargs: Any) -> list[float]:
        """
        Embed text using OpenAI Embedding's async function.

        For text longer than max_tokens, chunk texts into max_tokens, embed each chunk, then combine using weighted average.
        """
        token_chunks = chunk_text(
            text=text, token_encoder=self.token_encoder, max_tokens=self.max_tokens
        )
        chunk_embeddings = []
        chunk_lens = []
        embedding_results = await asyncio.gather(*[
            self._aembed_with_retry(chunk, **kwargs) for chunk in token_chunks
        ])
        embedding_results = [result for result in embedding_results if result[0]]
        chunk_embeddings = [result[0] for result in embedding_results]
        chunk_lens = [result[1] for result in embedding_results]
        chunk_embeddings = np.average(chunk_embeddings, axis=0, weights=chunk_lens)  # type: ignore
        chunk_embeddings = chunk_embeddings / np.linalg.norm(chunk_embeddings)
        return chunk_embeddings.tolist()

    def _embed_with_retry(
        self, text: str | tuple, **kwargs: Any
    ) -> tuple[list[float], int]:
        try:
            retryer = Retrying(
                stop=stop_after_attempt(self.max_retries),
                wait=wait_exponential_jitter(max=10),
                reraise=True,
                retry=retry_if_exception_type(self.retry_error_types),
            )
            for attempt in retryer:
                with attempt:
                    embedding = (
                        OllamaEmbeddings(
                            model=self.model,
                        ).embed_query(text)
                        or []
                    )
                    return (embedding, len(text))
        except RetryError as e:
            self._reporter.error(
                message="Error at embed_with_retry()",
                details={self.__class__.__name__: str(e)},
            )
            return ([], 0)
        else:
            # TODO: why not just throw in this case?
            return ([], 0)

    async def _aembed_with_retry(
        self, text: str | tuple, **kwargs: Any
    ) -> tuple[list[float], int]:
        try:
            retryer = AsyncRetrying(
                stop=stop_after_attempt(self.max_retries),
                wait=wait_exponential_jitter(max=10),
                reraise=True,
                retry=retry_if_exception_type(self.retry_error_types),
            )
            async for attempt in retryer:
                with attempt:
                    embedding = (
                        await OllamaEmbeddings(
                            model=self.model,
                        ).embed_query(text) or [] )
                    return (embedding, len(text))
        except RetryError as e:
            self._reporter.error(
                message="Error at embed_with_retry()",
                details={self.__class__.__name__: str(e)},
            )
            return ([], 0)
        else:
            # TODO: why not just throw in this case?
            return ([], 0)
```
#### ä¿®æ”¹é¡¹ç›®è·¯å¾„ä¸‹çš„settings.yamlæ–‡ä»¶
ä»¥ä¸‹æ˜¯å¸¸ç”¨å‚æ•°çš„ä¿®æ”¹è¯´æ˜ï¼š
```yaml
llm:
    api_key: ollama             # è¿™ä¸ªå¡«ä»€ä¹ˆéƒ½å¯ä»¥ï¼Œä½¿ç”¨ollamaè°ƒç”¨æœ¬åœ°å¤§æ¨¡å‹ä¸éœ€è¦api_key
    model: your_model_name      # æœ¬åœ°å¤§æ¨¡å‹çš„åç§°ï¼Œå¿…é¡»ä¿®æ”¹ï¼ï¼
    max_tokens: 2000            # æœ€å¤§tokenæ•°é‡ï¼Œå¯æ ¹æ®ç¡¬ä»¶é…ç½®è°ƒæ•´
    request_timeout: 180        # è¯·æ±‚è¶…æ—¶æ—¶é—´ï¼Œå¯æ ¹æ®ç¡¬ä»¶é…ç½®è°ƒæ•´
    api_base: http://localhost:11434/v1  # è°ƒç”¨ollamaçš„LLMçš„åœ°å€ï¼Œå¿…é¡»ä¿®æ”¹ï¼ï¼ç«¯å£å·æŒ‰å®é™…æƒ…å†µä¿®æ”¹
    concurrent_requests: 8      # å¹¶å‘è¯·æ±‚æ•°ï¼Œå¯æ ¹æ®ç¡¬ä»¶é…ç½®è°ƒæ•´

embeddings:
    llm:
        api_key: ollama         # åŒæ ·å¡«ä»€ä¹ˆéƒ½å¯ä»¥
        model: your_model_name  # åŒæ ·ä¿®æ”¹ï¼ï¼æ³¨æ„ï¼Œéœ€è¦ä¿®æ”¹æºç å¤„è°ƒç”¨ollamaEmbeddingçš„åœ°æ–¹ã€‚
        api_base: http://localhost:11434/api  # ä¿®æ”¹embeddingçš„è°ƒç”¨åœ°å€ï¼Œå¿…é¡»ä¿®æ”¹ï¼ï¼ã€‚ç«¯å£å·æŒ‰å®é™…æƒ…å†µä¿®æ”¹ã€‚

chunks:
    size: 600                   # ä¿®æ”¹æ–‡æœ¬åˆ†å—å¤§å°

storage:
    base_dir: "your_store_path"     # ä¿®æ”¹å­˜å‚¨è·¯å¾„ï¼Œä¹Ÿå¯ä»¥é€šè¿‡è¿è¡Œå‘½ä»¤æ—¶æ·»åŠ å‚æ•°ä»¥å®ç°åŒæ ·çš„æ•ˆæœ

update_index_storage:
    #base_dir: "your_store_path"    # è‹¥å¯ç”¨è¯¥å‚æ•°ï¼ŒGraphRAGå°†å¼€å¯å¢é‡åŠŸèƒ½ï¼Œå¢é‡åçš„æ•°æ®å°†ä¿å­˜åœ¨è¯¥æ–‡ä»¶å¤¹

reporting:
    base_dir: "your_log_path"   # ä¿®æ”¹æ—¥å¿—å­˜å‚¨è·¯å¾„

entity_extraction:
    entity_types: [type1, type2, Â·Â·Â·, type_n]  # æŒ‡å®šLLMæå–å®ä½“çš„ç±»å‹

summarize_descriptions:
    max_length: 800             # LLMç”Ÿæˆæ‘˜è¦çš„æœ€å¤§é•¿åº¦

community_reports:
    max_length: 4000            # LLMç”Ÿæˆç¤¾åŒºæŠ¥å‘Šçš„æœ€å¤§é•¿åº¦
    max_input_length: 10000     # ç”Ÿæˆç¤¾åŒºæŠ¥å‘Šæ—¶çš„æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦
```

### LightRAG
LightRAGå®˜æ–¹å·²ç»æ”¯æŒäº†ä½¿ç”¨ollamaæ¨¡å‹è°ƒç”¨ï¼Œæ•…å¯ä»¥å‚è€ƒ[LightRAG][LightRAG_github]å®˜æ–¹æ–‡æ¡£çš„***Using Ollama Models***å†…å®¹
#### åˆå§‹åŒ–RAGç³»ç»Ÿ
é‡‡ç”¨å®˜æ–¹çš„ç¤ºä¾‹ï¼Œå¹¶åŠ ä»¥ä¿®æ”¹ã€‚
```python
import os
import logging
from lightrag import LightRAG, QueryParam
from lightrag.llm import ollama_model_complete, ollama_embedding
from lightrag.utils import EmbeddingFunc
from save_latest_output import save_backup 

WORKING_DIR = "your_working_dir"

logging.basicConfig(format="%(levelname)s:%(message)s", level=logging.INFO)

if not os.path.exists(WORKING_DIR):
    os.mkdir(WORKING_DIR)

rag = LightRAG(
    working_dir=WORKING_DIR,                # æŒ‡å®šRAGç³»ç»Ÿçš„å·¥ä½œç›®å½•
    llm_model_func=ollama_model_complete,   # åœ¨ä½¿ç”¨ollamaæ¨¡å‹æ—¶ï¼Œéœ€è¦æŒ‡å®šè¯¥å‚æ•°
    llm_model_name="your_model_name",           # æŒ‡å®šollamaæ¨¡å‹çš„åç§°
    llm_model_max_async=16,                 # æŒ‡å®šollamaæ¨¡å‹çš„æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
    llm_model_max_token_size=32768,         # æŒ‡å®šæœ€å¤§ä¸Šä¸‹æ–‡
    chunk_token_size=600,                   # æŒ‡å®šæ–‡æœ¬åˆ†å—å¤§å°
    entity_summary_to_max_tokens=800,       # æŒ‡å®šLLMç”Ÿæˆæ‘˜è¦çš„æœ€å¤§é•¿åº¦

    # è¯¥å‚æ•°æŒ‡å®šollamaæœåŠ¡åœ°å€ï¼ŒåŒæ—¶éœ€è¦æ‰‹åŠ¨è®¾ç½®num_ctxå‚æ•°ä»¥è¾¾åˆ°ç›®æ ‡æœ€å¤§ä¸Šä¸‹æ–‡é•¿åº¦ï¼ˆollamaä¼šé»˜è®¤é™åˆ¶ä¸Šä¸‹æ–‡é•¿åº¦ä¸ºæŸä¸ªå€¼ï¼‰
    llm_model_kwargs={"host": "http://localhost:11434", "options": {"num_ctx": 32768}}, 

    # è¯¥å‚æ•°æŒ‡å®šollamaæ¨¡å‹çš„embeddingå‡½æ•°ï¼ŒåŒæ—¶éœ€è¦æ‰‹åŠ¨è®¾ç½®embed_modelå‚æ•°ä»¥è°ƒç”¨ollamaæ¨¡å‹
    embedding_func=EmbeddingFunc(
        embedding_dim=1024,
        max_token_size=8192,
        func=lambda texts: ollama_embedding(
            texts, embed_model="your_model_name", host="http://localhost:11434"
        ),
    ),
)
```

## è¿è¡ŒRAGç³»ç»Ÿ
### è¿è¡ŒGraphRAG
å› æœ¬é¡¹ç›®ä½¿ç”¨ollamaéƒ¨ç½²æœ¬åœ°å¤§æ¨¡å‹ï¼Œè¦æ­£å¸¸è¿è¡ŒGraphRAGï¼Œéœ€è¦æŒ‰å®é™…æƒ…å†µè¿›è¡Œé…ç½®ï¼Œå¯[å‚è€ƒä¸Šæ–¹å†…å®¹](#ä¿®æ”¹graphragæºç )è¿›è¡Œé…ç½®ã€‚
#### 1. åˆå§‹åŒ–é¡¹ç›®æ–‡ä»¶
åˆ›å»ºé¡¹ç›®æ–‡ä»¶å¤¹
```bash
mkdir TestGraphRAG
```
ä½¿ç”¨å‘½ä»¤åˆå§‹åŒ–é¡¹ç›®æ–‡ä»¶å¤¹
```bash
python -m graphrag init --root TestGraphRAG
```
æ­¤æ—¶ä¼šåœ¨TestGraphRAGæ–‡ä»¶å¤¹ä¸‹ç”Ÿæˆsettings.yamlã€.envã€promptsæ–‡ä»¶ï¼Œç”¨äºé…ç½®RAGç³»ç»Ÿçš„å‚æ•°ã€‚  
ï¼ˆå¯é€‰ï¼‰GraphRAGå¯ä»¥æŒ‰ç…§ç”¨æˆ·éœ€æ±‚è‡ªè¡Œè°ƒæ•´æç¤ºè¯promptï¼Œåªéœ€æ‰§è¡Œå‘½ä»¤ï¼Œè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒ[å®˜æ–¹æ–‡æ¡£][GraphRAG]ã€‚
```bash
python -m graphrag prompt-tune --root ~/GraphRAG [é…ç½®å‚æ•°]
```
#### 2. å»ºç«‹ç´¢å¼•
åœ¨TestGraphRAGæ–‡ä»¶å¤¹ä¸‹åˆ›å»ºinputæ–‡ä»¶å¤¹ï¼Œç”¨ä»¥å­˜æ”¾åŸå§‹è¯­æ–™ã€‚
```bash
cd TestGraphRAG
mkdir input
```
åœ¨æ”¾å…¥è¾“å…¥æ•°æ®å¹¶ä¸”é…ç½®å¥½settings.yamlæ–‡ä»¶åï¼Œæ‰§è¡Œå‘½ä»¤å»ºç«‹ç´¢å¼•ã€‚
```bash
cd ..
python -m graphrag index --root TestGraphRAG
```
ç­‰å¾…è¿è¡Œç»“æŸï¼ŒæˆåŠŸå»ºç«‹ç´¢å¼•ã€‚
ï¼ˆå¯é€‰ï¼‰GraphRAGæ”¯æŒå¢é‡æ›´æ–°ï¼Œéœ€è¦é…ç½®settings.yamlæ–‡ä»¶ä¸­çš„update_index_storageå‚æ•°ï¼Œå¹¶è¿è¡Œå‘½ä»¤å³å¯ï¼Œè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒ[å®˜æ–¹æ–‡æ¡£][GraphRAG_github]ã€‚
```bash
python -m graphrag update --root_dir TestGraphRAG
```
#### 3. æ‰§è¡ŒæŸ¥è¯¢
GraphRAGæ”¯æŒå¤šç§æŸ¥è¯¢æ–¹å¼ï¼Œè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒ[å®˜æ–¹æ–‡æ¡£][GraphRAG]ï¼Œè¿™é‡Œä»¥å…¨å±€æœç´¢ä¸ºä¾‹å­ã€‚
```bash
python -m graphrag query --root TestGraphRAG --method global "your_query"
```

### è¿è¡ŒLightRAG
å› æœ¬é¡¹ç›®ä½¿ç”¨ollamaéƒ¨ç½²æœ¬åœ°å¤§æ¨¡å‹ï¼Œæ•…LightRAGçš„é…ç½®å‚æ•°ä¹Ÿéœ€è¦å¾€ollamaçš„æ–¹å‘é ã€‚
#### 1. å»ºç«‹ç´¢å¼•ï¼Œç”Ÿæˆå›¾ç´¢å¼•æ–‡ä»¶
æ–°å»ºä¸€ä¸ªpythonæ–‡ä»¶ï¼Œå‚è€ƒ[ä¸Šæ–¹å†…å®¹](#åˆå§‹åŒ–RAGç³»ç»Ÿ)é…ç½®LightRAGå‚æ•°ï¼Œåˆå§‹åŒ–LightRAGå¯¹è±¡ã€‚åˆå§‹åŒ–åï¼Œè°ƒç”¨LightRAGå¯¹è±¡çš„``insert()``æ–¹æ³•å»ºç«‹ç´¢å¼•ï¼Œå‚æ•°ä¸ºä¼ å…¥çš„æ–‡æ¡£æ•°æ®ï¼Œä¸¾ä¸ªä¾‹å­ã€‚
```python
with open("input/example.txt", "r", encoding="utf-8") as f:
    rag.insert(f.read())
```
ï¼ˆå¯é€‰ï¼‰LightRAGå»ºç«‹çš„ç´¢å¼•å¯ä»¥åœ¨Neo4jä¸Šå­˜å‚¨ï¼Œè¿›è¡Œå¯è§†åŒ–ï¼Œè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒ[å®˜æ–¹æ–‡æ¡£][LightRAG_github]ã€‚è¦ä½¿ç”¨Neo4jå­˜å‚¨ï¼Œéœ€è¦é…ç½®å¥½Neo4jçš„å‚æ•°ã€‚
```bash
export NEO4J_URI="neo4j://localhost:7687"
export NEO4J_USERNAME="your_username"
export NEO4J_PASSWORD="your_password"
```
åŒæ—¶ï¼Œåœ¨åˆå§‹åŒ–LightRAGå¯¹è±¡æ—¶ï¼Œè®¾ç½®å‚æ•°``graph_storage="Neo4JStorage"``ï¼Œå³å¯å®ç°å°†ç´¢å¼•æ•°æ®å­˜å‚¨åˆ°Neo4jä¸­ã€‚

#### 2. æ‰§è¡ŒæŸ¥è¯¢
åœ¨åˆå§‹åŒ–LightRAGå¯¹è±¡åï¼Œè°ƒç”¨å¯¹è±¡çš„``query()``æ–¹æ³•è¿›è¡ŒæŸ¥è¯¢ï¼Œå‚æ•°ä¼ å…¥æŸ¥è¯¢è¯­å¥ä¸æŸ¥è¯¢æ¨¡æ¿ï¼ŒæŸ¥è¯¢æ¨¡æ¿å¯ä»¥è°ƒæ•´æŸ¥è¯¢è¿”å›çš„ç»“æœç±»å‹ï¼Œè¯¦ç»†ä¿¡æ¯è¯·å‚è€ƒ[å®˜æ–¹æ–‡æ¡£][LightRAG_github]ã€‚æŸ¥è¯¢æ¨¡æ¿çš„çš„å‚æ•°å¦‚ä¸‹ã€‚
```python
class QueryParam:
    mode: Literal["local", "global", "hybrid", "naive"] = "global"   # ä»¥ä»€ä¹ˆæ–¹å¼æŸ¥è¯¢
    only_need_context: bool = False                                  # æ˜¯å¦åªè¿”å›æŸ¥è¯¢åˆ°çš„ä¸Šä¸‹æ–‡
    response_type: str = "Multiple Paragraphs"                       # è§„å®šç”Ÿæˆç›¸åº”çš„ç±»å‹
    # Number of top-k items to retrieve; corresponds to entities in "local" mode and relationships in "global" mode.
    top_k: int = 60
    # Number of tokens for the original chunks.
    max_token_for_text_unit: int = 4000
    # Number of tokens for the relationship descriptions
    max_token_for_global_context: int = 4000
    # Number of tokens for the entity descriptions
    max_token_for_local_context: int = 4000
```
ä¸¾ä¸ªä¾‹å­ï¼Œæˆ‘æƒ³ä»¥``global``çš„æ–¹å¼æŸ¥è¯¢``"å“ªäº›å“ç§è¢«ç§°ä¸ºçº¢èŒ¶ï¼Ÿ"``ï¼Œå¹¶å¸Œæœ›è¿”å›çš„ç»“æœç±»å‹ä¸º``"å°½å¯èƒ½å¤šçš„å›ç­”"``ï¼Œå¹¶é™åˆ¶æ£€ç´¢å…³ç³»çš„æ•°é‡ä¸º40ä¸ªï¼Œåˆ™å¯ä»¥è°ƒç”¨å¦‚ä¸‹ä»£ç ã€‚
```python
rag.query("å“ªäº›å“ç§è¢«ç§°ä¸ºçº¢èŒ¶ï¼Ÿ", param=QueryParam(mode="global", only_need_context=False, top_k=40, response_type='å°½å¯èƒ½å¤šçš„å›ç­”', max_token_for_global_context=32768))
```

## é¡¹ç›®æ–‡ä»¶è§£é‡Š
### GraphRAGé¡¹ç›®æ–‡ä»¶
åœ¨GraphRAGé¡¹ç›®æ–‡ä»¶å¤¹ä¸‹ï¼Œoutputå…±æœ‰3æ¬¡ç´¢å¼•ç»“æœï¼Œfirstç»“æœä»…ä¼ å…¥â€œ**åˆ¶èŒ¶æŠ€è‰º**â€çš„æ–‡æ¡£ï¼Œè€Œsecondã€thirdç»“æœä¾æ¬¡ä»¥å¢é‡çš„å½¢å¼ä¼ å…¥â€œ**èŒ¶å¶ç—…å®³**â€ä¸â€œ**èŒ¶å¶å®³è™«**â€çš„æ–‡æ¡£ã€‚  
#### é‡åˆ°çš„é—®é¢˜
- è¯·æ±‚è¶…æ—¶â€”â€”å•æ¬¡LLMè¯·æ±‚å¤„ç†æ—¶é—´å¤šæ¬¡è¶…è¿‡24minï¼Œå·¨å¤§çš„æ—¶é—´èµ„æºæ¶ˆè€—ã€‚
- Ollamaä¸Šä¸‹æ–‡é™åˆ¶â€”â€”GraphRAGä½¿ç”¨OpenAIæ¥å£ï¼Œæ²¡æœ‰å†…ç½®çš„Ollamaæ¥å£ï¼Œå‚è€ƒGitHubç¤¾åŒºçš„è§£å†³æ–¹æ³•ï¼Œä¾æ—§ä¼šæœ‰å¥‡å¥‡æ€ªæ€ªçš„æŠ¥é”™ã€‚
- è¿è¡Œä¸ç¨³å®šâ€”â€”æœ‰æ—¶èƒ½é¡ºåˆ©è·‘å®Œæ•´ä¸ªæµç¨‹ï¼Œæœ‰æ—¶ç–¯ç‹‚æŠ¥é”™ï¼Œä»å®ä½“æå–æ­¥éª¤å¼€å§‹å°±å‡ºé”™  
  
æ‰€ä»¥GraphRAGé¡¹ç›®æ–‡ä»¶ä»…ä»…ä¼ å…¥3ä¸ªæ–‡æ¡£ä¾¿æ­¢æ­¥äº†ã€‚

### LightRAGé¡¹ç›®æ–‡ä»¶
åœ¨LightRAGé¡¹ç›®æ–‡ä»¶å¤¹ä¸‹ï¼Œoutputæ–‡ä»¶å¤¹å­˜å‚¨ç€æœ€æ–°ç”Ÿæˆçš„ç´¢å¼•æ–‡ä»¶ï¼ŒåŒæ—¶Backupæ–‡ä»¶å¤¹å­˜å‚¨ç€å†å²ç´¢å¼•æ–‡ä»¶ã€‚  
ç›®å‰å·²ä¼ å…¥è¶…è¿‡600æ¡æ¡ç›®æ–‡æ¡£æ•°æ®ã€‚

### Ragasé¡¹ç›®æ–‡ä»¶
åœ¨Ragasé¡¹ç›®æ–‡ä»¶å¤¹ä¸‹ï¼Œå­˜æ”¾ç€å°è¯•ä½¿ç”¨``ragas``åº“è‡ªåŠ¨ç”ŸæˆRAGè¯„åˆ†æ•°æ®é›†çš„notebookæ–‡ä»¶ï¼Œä»¥åŠç”Ÿæˆå‡ºçš„æµ‹è¯•æ•°æ®ã€‚  


----------------------------------------------------------------
## TODO List:
- [ ] æ„å»ºç”¨äºè¯„ä¼°RAGç³»ç»Ÿçš„æ•°æ®é›†
- [ ] æ„å»ºç”¨äºç”¨æˆ·äº¤äº’çš„WebUI
----------------------------------------------------------------

[DrissionPage]: https://www.drissionpage.cn/
[DrissionPage_github]: https://github.com/g1879/DrissionPage
[Knowledge Graph]: https://mp.weixin.qq.com/s/7GkO5lX7ltXaMwH6tAN-RA
[GraphRAG_github]: https://github.com/microsoft/graphrag
[GraphRAG]: https://microsoft.github.io/graphrag/
[LightRAG_LearnOpenCV]: https://learnopencv.com/lightrag/
[LightRAG_github]: https://github.com/HKUDS/LightRAG
[Ollama]: https://ollama.com/
[Ollama_github]: https://github.com/ollama/ollama
[ragas]: https://github.com/explodinggradients/ragas
[RAGChecker]: https://github.com/amazon-science/RAGChecker
[CSDN_GraphRAG]: https://blog.csdn.net/gaotianhao123/article/details/140640415

## é¡¹ç›®ç»“æ„
```txt
TeaInfo-KG-RAG-Ollama
â”œâ”€assets
â”œâ”€Crawler
â”œâ”€examples
â”‚  â””â”€data
â”œâ”€GraphRAG
â”‚  â”œâ”€input
â”‚  â”œâ”€output
â”‚  â”‚  â”œâ”€first
â”‚  â”‚  â”œâ”€lancedb
â”‚  â”‚  â”œâ”€second
â”‚  â”‚  â””â”€third
â”‚  â””â”€prompts
â”œâ”€LightRAG
â”‚  â”œâ”€Backup
â”‚  â”œâ”€input
â”‚  â”œâ”€output
â”‚  â””â”€src
â””â”€Ragas
    â”œâ”€src
    â””â”€æµ‹è¯•é›†å‚è€ƒæ–‡æ¡£
```